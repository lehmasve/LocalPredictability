{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finance - Signal Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Empty the workspace\n",
    "rm(list = ls())\n",
    "\n",
    "# Set Folder-Path\n",
    "path <- \"~/LocalPredictability\" # Change to project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "library(\"tidyverse\")\n",
    "library(\"lubridate\")\n",
    "library(\"purrr\")\n",
    "library(\"magrittr\")\n",
    "library(\"glue\")\n",
    "library(\"readr\")\n",
    "library(\"readxl\")\n",
    "library(\"pbapply\")\n",
    "library(\"roll\")\n",
    "library(\"lightgbm\")\n",
    "library(\"kableExtra\")\n",
    "library(\"quanteda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load Custom Functions\n",
    "source(glue(\"{path}/Code/_helpers.R\"))\n",
    "\n",
    "# Convert Jupyter Notebook to R script\n",
    "convert_ipynb_to_r(glue(\"{path}/Code/finance_signal_sets.ipynb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Create Economic-Financial / Technical Signal Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Get Dates\n",
    "# Extract from Return-Data\n",
    "dates <- read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/vwretd.csv\")) %>%\n",
    "  rename(Date = DATE) %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  filter(Date <= ymd(\"2021-12-31\")) %>%\n",
    "  drop_na(vwretd) %>%\n",
    "  pull(Date)\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### T-Bill, Yield and Term Spread\n",
    "read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/FRED_H15.csv\")) %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  rename(TBL3M = `DTB3`, CMT10Y = `DGS10`) %>%\n",
    "  mutate(\n",
    "    across(-Date, ~ 0.01 * as.numeric(.x)),\n",
    "    TSP1 = CMT10Y - TBL3M\n",
    "  ) %>%\n",
    "  fill(!Date, .direction = \"down\") %>%\n",
    "  dplyr::select(Date, TBL3M, TSP1) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/interest_rates.rds\")) %>%\n",
    "  mutate(Rfree = (1 + dplyr::lag(TBL3M, n = 1L)) ** (1 / 252) - 1) %>%\n",
    "  dplyr::select(Date, Rfree) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/rfree.rds\"),\n",
    "            compress = \"gz\")\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Equity Premium\n",
    "# Load Risk-Free Rate\n",
    "Rfree <- read_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/rfree.rds\"))\n",
    "\n",
    "# CRSP Returns\n",
    "read_csv(paste0(path, \"/Data/ES1/P_Signals/Econ_Fin/Raw/vwretd.csv\")) %>%\n",
    "  rename(Date = DATE, CRSP_SPvw = vwretd) %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  left_join(Rfree, by = \"Date\") %>%\n",
    "  mutate(equity_premium = CRSP_SPvw - Rfree) %>%\n",
    "  drop_na(equity_premium) %>%\n",
    "  dplyr::select(Date, equity_premium) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/equity_premium.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"Rfree\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Dividend-Price-Ratio\n",
    "# Dividends\n",
    "div <- read_csv2(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/divm.csv\")) %>%\n",
    "  rename(year_month = yyyymm) %>%\n",
    "  mutate(year_month = ym(year_month))\n",
    "\n",
    "# S&P 500 Index\n",
    "read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/spind.csv\")) %>%\n",
    "  rename(index = Close) %>%\n",
    "  mutate(Date = ymd(Date),\n",
    "         year_month = floor_date(Date, \"month\")) %>%\n",
    "  left_join(div, by = \"year_month\") %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  mutate(dp = log(dplyr::lag(D12, n = 1L)) - log(index)) %>%\n",
    "  dplyr::select(Date, dp) %>%\n",
    "  fill(!Date, .direction = \"down\") %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/dp_ratio.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"div\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Exchange Rates\n",
    "read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/FRED_H10.csv\")) %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  mutate(across(-Date, ~ as.numeric(.x))) %>%\n",
    "  mutate(across(ends_with(\"_USD\"), ~ 1.0 / .x)) %>%\n",
    "  rename_with(~ ifelse(str_ends(., \"_USD\"), paste0(\"USD_\", str_remove(., \"_USD\")), .)) %>%\n",
    "  mutate(across(-Date, ~ (.x - dplyr::lag(.x, n = 1L)) / dplyr::lag(.x, n = 1L))) %>%\n",
    "  dplyr::select(Date, starts_with(\"USD_\")) %>%\n",
    "  dplyr::select(-c(USD_MYR, USD_LKR)) %>%\n",
    "  fill(!Date, .direction = \"down\") %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/exchange_rates.rds\"),\n",
    "            compress = \"gz\")\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Moving-Average Indicator\n",
    "# Time Periods\n",
    "periods <- c(1*21, 3*21, 6*21, 9*21, 12*21)\n",
    "\n",
    "# Load S&P 500 Index\n",
    "spind <- read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/spind.csv\")) %>%\n",
    "  rename(Index = Close) %>%\n",
    "  filter(Date %in% dates)\n",
    "\n",
    "# Calculate Moving Averages\n",
    "for (period in periods) {\n",
    "  period_var <- glue(\"ma_D{period}\")\n",
    "  spind <- spind %>%\n",
    "    mutate(!!period_var := roll::roll_mean(Index, width = period))\n",
    "}\n",
    "\n",
    "# Generate relevant combinations of periods\n",
    "combinations <- expand.grid(i = seq_along(periods), j = seq_along(periods)) %>%\n",
    "  filter(i < j)\n",
    "\n",
    "# Compute MA-Indicator\n",
    "ma_indicator <- purrr::pmap(combinations, function(i, j) {\n",
    "  new_var <- glue(\"MA_D{periods[i]}_D{periods[j]}\")\n",
    "  left_var <- glue(\"ma_D{periods[i]}\")\n",
    "  right_var <- glue(\"ma_D{periods[j]}\")\n",
    "  spind %>%\n",
    "    mutate(!!new_var := (spind[[left_var]] - spind[[right_var]]) / spind[[right_var]]) %>%\n",
    "    dplyr::select(Date, !!new_var)\n",
    "}) %>%\n",
    "  purrr::reduce(left_join, by = c(\"Date\"))\n",
    "\n",
    "# Save\n",
    "ma_indicator %>%\n",
    "  dplyr::select(Date, starts_with(\"MA_D\", ignore.case = FALSE)) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/ma_indicator.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"spind\", \"periods\", \"combinations\", \"ma_indicator\", \"period_var\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Price Momentum\n",
    "# Time Periods\n",
    "pm_periods <- c(1, 3, 5, 1 * 21, 3 * 21, 6 * 21, 9 * 21, 12 * 21)\n",
    "\n",
    "# Load S&P 500 Index\n",
    "pmom_indicator <- read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/spind.csv\")) %>%\n",
    "  rename(Index = Close) %>%\n",
    "  filter(Date %in% dates)\n",
    "\n",
    "# Compute Momentum\n",
    "for (period in pm_periods) {\n",
    "  period_var <- glue(\"PMOM_D{period}\")\n",
    "  pmom_indicator <- pmom_indicator %>%\n",
    "    mutate(!!period_var := (Index - dplyr::lag(Index, n = period)) / dplyr::lag(Index, n = period))\n",
    "}\n",
    "\n",
    "# Save\n",
    "pmom_indicator %>%\n",
    "  dplyr::select(Date, starts_with(\"PMOM_D\", ignore.case = FALSE)) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/pmom_indicator.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"pmom_indicator\", \"period_var\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Volume Indicators\n",
    "# Load Volume Data\n",
    "vol <- read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/spvol.csv\"))\n",
    "\n",
    "# Load S&P 500 Index Data\n",
    "spind <- read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/spind.csv\")) %>%\n",
    "  rename(Index = Close)\n",
    "\n",
    "# Combine Data\n",
    "data <- spind %>%\n",
    "  left_join(vol, by = \"Date\") %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  mutate(\n",
    "    RVol = (Volume - dplyr::lag(Volume, n = 1L)) / dplyr::lag(Volume, n = 1L),\n",
    "    D = dplyr::if_else(Index >= dplyr::lag(Index), 1, -1),\n",
    "    OBV = roll::roll_sum(Volume * D, width = n(), min_obs = 1)\n",
    "  ) %>%\n",
    "  dplyr::select(Date, starts_with(\"RVol\"), OBV)\n",
    "\n",
    "# Time Periods\n",
    "periods <- c(1*21, 3*21, 6*21, 9*21, 12*21)\n",
    "\n",
    "# Calculate OBV-Moving-Averages\n",
    "for (period in periods) {\n",
    "  period_var <- glue(\"OBV_D{period}\")\n",
    "  data <- data %>%\n",
    "    mutate(!!period_var := roll::roll_mean(OBV, width = period))\n",
    "}\n",
    "\n",
    "# Generate combinations of periods\n",
    "combinations <- expand.grid(i = seq_along(periods), j = seq_along(periods)) %>%\n",
    "  filter(i < j)\n",
    "\n",
    "# Compute Volume-Indicator\n",
    "vol_indicator <- purrr::pmap(combinations, function(i, j) {\n",
    "  new_var   <- glue(\"VOL_D{periods[i]}_D{periods[j]}\")\n",
    "  left_var  <- glue(\"OBV_D{periods[i]}\")\n",
    "  right_var <- glue(\"OBV_D{periods[j]}\")\n",
    "  data %>%\n",
    "    mutate(!!new_var := (data[[left_var]] - data[[right_var]]) / data[[right_var]]) %>%\n",
    "    dplyr::select(Date, !!new_var)\n",
    "}) %>%\n",
    "  purrr::reduce(left_join, by = c(\"Date\"))\n",
    "\n",
    "# Save\n",
    "vol_indicator %>%\n",
    "  left_join(data, by = \"Date\") %>%\n",
    "  dplyr::select(Date,\n",
    "         starts_with(\"RVol\"),\n",
    "         starts_with(\"VOL_D\", ignore.case = FALSE)) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/vol_indicator.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"vol\", \"spind\", \"data\", \"periods\", \"combinations\", \"vol_indicator\", \"period_var\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Commodities\n",
    "read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/GSCITOT.csv\")) %>%\n",
    "  rename(Date = Date_) %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  arrange(Date) %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  mutate(GSCITOT = (Close_ - dplyr::lag(Close_, n = 1L)) / dplyr::lag(Close_, n = 1L)) %>%\n",
    "  dplyr::select(Date, GSCITOT) %>%\n",
    "  fill(GSCITOT, .direction = \"down\") %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/commodity_index.rds\"),\n",
    "            compress = \"gz\")\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Gold\n",
    "read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/GOLDBLN.csv\")) %>%\n",
    "  rename(Date = Date_) %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  arrange(Date) %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  distinct(Date, .keep_all = TRUE) %>%\n",
    "  mutate(GOLDBLN = (Close_ - dplyr::lag(Close_, n = 1)) / dplyr::lag(Close_, n = 1)) %>%\n",
    "  dplyr::select(Date, GOLDBLN) %>%\n",
    "  fill(GOLDBLN, .direction = \"down\") %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/goldbln.rds\"),\n",
    "            compress = \"gz\")\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Realized Volatility and Vix\n",
    "# Load VIX Data\n",
    "vix <- read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/vix.csv\")) %>%\n",
    "  rename(Date = DATE, vix = CLOSE) %>%\n",
    "  dplyr::select(Date, vix) %>%\n",
    "  mutate(Date = mdy(Date)) %>%\n",
    "  filter(Date %in% dates)\n",
    "\n",
    "# Calculate Realized Volatility\n",
    "read_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/equity_premium.rds\")) %>%\n",
    "  left_join(vix, by = \"Date\") %>%\n",
    "  mutate(\n",
    "    vola = roll::roll_sum((equity_premium ** 2), width = 63),\n",
    "    vola_mele_vix = 100 * sqrt(pi / 2) * sqrt(12 * 21) * roll::roll_mean(x = abs(equity_premium), width = 12 * 21),\n",
    "    vola_mele_vix = ifelse(is.na(vix), vola_mele_vix, vix)\n",
    "  ) %>%\n",
    "  dplyr::select(Date, vola, vola_mele_vix) %>%\n",
    "  fill(!Date, .direction = \"down\") %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/volatility.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"vix\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Sentiment\n",
    "# Load Michigan Consumer Sentiment Data\n",
    "sent <- read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/UMCSENT.csv\")) %>%\n",
    "  rename(year_month = DATE, sentiment = UMCSENT) %>%\n",
    "  mutate(sentiment = dplyr::lag(sentiment, n = 1L))\n",
    "\n",
    "# Time Periods\n",
    "senti_periods <- c(1, 3, 6, 9, 12)\n",
    "\n",
    "# Calculate Sentiment Momentum\n",
    "for (period in senti_periods) {\n",
    "  new_var <- glue(\"smom_M{period}\")\n",
    "  sent <- sent %>%\n",
    "    mutate(!!new_var := sentiment - dplyr::lag(sentiment, n = period))\n",
    "}\n",
    "\n",
    "# Load Price Momentum Data\n",
    "pmom <- read_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/pmom_indicator.rds\")) %>%\n",
    "  mutate(year_month = floor_date(Date, \"month\"))\n",
    "\n",
    "# Merge sentiment and price momentum data\n",
    "data <- pmom %>%\n",
    "  left_join(sent, by = \"year_month\") %>%\n",
    "  dplyr::select(Date, starts_with(\"smom_M\"), starts_with(\"PMOM_D\"))\n",
    "\n",
    "# Generate combinations of periods\n",
    "combinations <- expand.grid(i = senti_periods,\n",
    "                            j = pm_periods)\n",
    "\n",
    "# Compute interactions between sentiment and price momentum\n",
    "interactions <- purrr::pmap(combinations, function(i, j) {\n",
    "  new_var <- glue(\"SPMOM_INT_M{i}_D{j}\")\n",
    "  left_var <- glue(\"smom_M{i}\")\n",
    "  right_var <- glue(\"PMOM_D{j}\")\n",
    "  data %>%\n",
    "    mutate(!!new_var := data[[left_var]] * data[[right_var]]) %>%\n",
    "    dplyr::select(Date, !!new_var)\n",
    "}) %>%\n",
    "  purrr::reduce(left_join, by = c(\"Date\"))\n",
    "\n",
    "# Save\n",
    "data %>%\n",
    "  left_join(interactions, by = \"Date\") %>%\n",
    "  dplyr::select(Date, starts_with(\"SPMOM_INT\")) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/sentiment.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"sent\", \"senti_periods\", \"pmom\", \"data\", \"combinations\", \"interactions\", \"new_var\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### World Indices\n",
    "# Function to process index data\n",
    "get_returns <- function(file_name, index_name, output_file) {\n",
    "  read_csv(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/Raw/{file_name}.csv\")) %>%\n",
    "    rename(Date = valuedate) %>%\n",
    "    mutate(Date = ymd(Date)) %>%\n",
    "    filter(Date %in% dates) %>%\n",
    "    mutate(!!index_name := (pi_ - dplyr::lag(pi_, n = 1)) / dplyr::lag(pi_, n = 1)) %>%\n",
    "    dplyr::select(Date, !!index_name) %>%\n",
    "    fill(!Date, .direction = \"down\") %>%\n",
    "    write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/{output_file}.rds\"), compress = \"gz\")\n",
    "}\n",
    "\n",
    "# Process each index\n",
    "get_returns(\"DJINDUS\", \"DJI\", \"djindus\")\n",
    "get_returns(\"IXIC\", \"IXIC\", \"ixic\")\n",
    "get_returns(\"HNGKNGI\", \"HSI\", \"hsi\")\n",
    "get_returns(\"JAPDOWA\", \"N225\", \"n225\")\n",
    "get_returns(\"KORCOMP\", \"KOSPI\", \"kospi\")\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Create Economic and Financial Data Set\n",
    "# Define file names\n",
    "file_names <- c(\"equity_premium\",\n",
    "                \"dp_ratio\", \"interest_rates\", \"volatility\",\n",
    "                \"ma_indicator\", \"pmom_indicator\", \"vol_indicator\",\n",
    "                \"sentiment\",\n",
    "                \"commodity_index\", \"goldbln\",\n",
    "                \"djindus\", \"ixic\", \"hsi\", \"n225\", \"kospi\",\n",
    "                \"exchange_rates\")\n",
    "\n",
    "# Load and Join\n",
    "fin_econ_set <- purrr::map(file_names, ~ read_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/{.x}.rds\"))) %>%\n",
    "  purrr::reduce(left_join, by = \"Date\")\n",
    "\n",
    "# Fill and Remove\n",
    "fin_econ_set <- fin_econ_set %>%\n",
    "  fill(!equity_premium, .direction = \"down\") %>%\n",
    "  drop_na(equity_premium) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/econ_fin_signals.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Display Dimensions\n",
    "cat(\"Number of Signals:\", ncol(fin_econ_set), \"\\n\")\n",
    "cat(\"Number of Observations:\", nrow(fin_econ_set), \"\\n\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"file_names\", \"fin_econ_set\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Create Text-based Signal Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Prepare Word-Count Data\n",
    "# Load and Prepare DFM\n",
    "dfm_daily <- read_rds(glue(\"{path}/Data/ES1/P_Signals/Text_Signals/Raw/dfm_daily.rds\")) %>%\n",
    "  quanteda::dfm_weight(scheme = \"prop\") %>%\n",
    "  quanteda::convert(to = \"data.frame\") %>%\n",
    "  rename(\"Date\" = doc_id) %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Text_Signals/text_signals.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Display Dimensions\n",
    "cat(\"Number of Signals:\", ncol(dfm_daily), \"\\n\")\n",
    "cat(\"Number of Observations:\", nrow(dfm_daily), \"\\n\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"dfm_daily\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Prepare Topic-Model Data\n",
    "# Load all files\n",
    "ctm_files <- list.files(glue(\"{path}/Data/ES1/P_Signals/Text_Signals/Raw/\"),\n",
    "                        pattern = \"^ctm_.*_topics_.*\\\\.csv$\",\n",
    "                        full.names = TRUE)\n",
    "\n",
    "# Read all csv files (topics)\n",
    "topic_data <- ctm_files %>%\n",
    "  map(read_csv) %>%\n",
    "  reduce(left_join, by = \"date\") %>%\n",
    "  rename(Date = date) %>%\n",
    "  filter(Date %in% dates) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/P_Signals/Text_Signals/topic_signals.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Display Dimensions\n",
    "cat(\"Number of Signals:\", ncol(topic_data), \"\\n\")\n",
    "cat(\"Number of Observations:\", nrow(topic_data), \"\\n\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"ctm_files\", \"topic_data\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Create External Point Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Rolling Mean of Equity Premium\n",
    "# Load Equity Premium\n",
    "ep <- read_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/equity_premium.rds\"))\n",
    "\n",
    "# Calculate rolling mean forecast\n",
    "pred_phm <- ep %>%\n",
    "  mutate(PHM = dplyr::lag(roll::roll_mean(equity_premium,\n",
    "                                          width = (5 * 252),\n",
    "                                          min_obs = 1),\n",
    "                          n = 1L)) %>%\n",
    "  dplyr::select(Date, PHM) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/F_Signals/phm.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"ep\", \"pred_phm\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Gradient Boosting Volatility Forecast\n",
    "# Load custom function\n",
    "source(paste0(path, \"/Code/_cmodels.R\"), local = TRUE)\n",
    "\n",
    "# Load Volatility Data\n",
    "volatility <- read_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/econ_fin_signals.rds\")) %>%\n",
    "  dplyr::select(Date, equity_premium, vola_mele_vix)\n",
    "\n",
    "# Create lagged variables\n",
    "for (i in 1:10) {\n",
    "  volatility <- volatility %>%\n",
    "    mutate(!!paste0(\"v\", i) := dplyr::lag(vola_mele_vix, n = i))\n",
    "}\n",
    "\n",
    "# Finalize data\n",
    "data <- volatility %>%\n",
    "  column_to_rownames(\"Date\") %>%\n",
    "  dplyr::select(-vola_mele_vix) %>%\n",
    "  drop_na() %>%\n",
    "  as.matrix()\n",
    "\n",
    "# Result-Object: Predictions\n",
    "pred_vola <- matrix(NA, nrow = nrow(volatility),\n",
    "                    ncol = 1, dimnames = list(as.character(volatility$Date),\n",
    "                                              \"Refi_GBM\"))\n",
    "\n",
    "# Set Time Parameter\n",
    "window_size <- 252 * 5\n",
    "t_start <- window_size\n",
    "t_end <- nrow(data) - 1\n",
    "t_seq <- seq(t_start, t_end)\n",
    "adj <- nrow(volatility) - nrow(data)\n",
    "\n",
    "# Set Tuning Parameter\n",
    "folds <- 5\n",
    "ntrees <- 500\n",
    "learning_rate <- 0.1\n",
    "n_core <- 1\n",
    "\n",
    "# Parallel-Backend\n",
    "cores <- 6\n",
    "cl <- parallel::makeCluster(cores)\n",
    "clusterExport(cl = cl, varlist = c(\"data\",\n",
    "                                   \"window_size\",\n",
    "                                   \"folds\",\n",
    "                                   \"ntrees\",\n",
    "                                   \"learning_rate\",\n",
    "                                   \"n_core\",\n",
    "                                   \"cm_gbm\"), envir = environment())\n",
    "clusterEvalQ(cl, library(\"lightgbm\"))\n",
    "pbo <- pbapply::pboptions(type = \"timer\")\n",
    "\n",
    "# Perform predictions in parallel\n",
    "pred_vola[t_seq + adj + 1, ] <- do.call(\"rbind\", pbapply::pblapply(cl = cl, X = t_seq, FUN = function(t) {\n",
    "\n",
    "  # Train Data\n",
    "  x_train <- data[(t - window_size + 1):t, -1, drop = FALSE]\n",
    "  y_train <- data[(t - window_size + 1):t,  1, drop = FALSE]\n",
    "\n",
    "  # Test Data\n",
    "  x_pred <- data[(t + 1), -1, drop = FALSE]\n",
    "\n",
    "  # Predict\n",
    "  pred <- cm_gbm(x_train,\n",
    "                 y_train,\n",
    "                 x_pred,\n",
    "                 folds,\n",
    "                 ntrees,\n",
    "                 learning_rate,\n",
    "                 n_core,\n",
    "                 t)\n",
    "\n",
    "  # Return Prediction\n",
    "  return(pred)\n",
    "}))\n",
    "\n",
    "# Stop Parallel Back-end\n",
    "parallel::stopCluster(cl)\n",
    "\n",
    "# Convert to Tibble and Save\n",
    "pred_vola <- pred_vola %>%\n",
    "  dplyr::as_tibble(rownames = \"Date\") %>%\n",
    "  dplyr::mutate(Date = ymd(Date)) %>%\n",
    "  readr::write_rds(glue(\"{path}/Data/ES1/F_Signals/refi_gbm.rds\"),\n",
    "                   compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"volatility\", \"data\", \"pred_vola\",\n",
    "            \"window_size\", \"t_start\", \"t_end\", \"t_seq\", \"adj\",\n",
    "            \"folds\", \"ntrees\", \"learning_rate\",\n",
    "            \"n_core\", \"cores\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Equally-Weighted Forecast Combination of DP + TBL\n",
    "# Load Custom Function\n",
    "source(glue(\"{path}/Code/_cmodels.R\"), local = TRUE)\n",
    "\n",
    "# Load Data\n",
    "econ_fin <- read_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/econ_fin_signals.rds\")) %>%\n",
    "  dplyr::select(Date, equity_premium, dp, TBL3M) %>%\n",
    "  rename(tbl = TBL3M) %>%\n",
    "  mutate(dp  = dplyr::lag(dp,  n = 1L),\n",
    "         tbl = dplyr::lag(tbl, n = 1L)) %>%\n",
    "  column_to_rownames(\"Date\")\n",
    "\n",
    "# Drop Na-Values\n",
    "data <- econ_fin %>%\n",
    "  drop_na() %>%\n",
    "  as.matrix()\n",
    "\n",
    "# Result-Object: Predictions\n",
    "pred_dp_tbl <- matrix(NA, nrow = nrow(econ_fin),\n",
    "                      ncol = 1, dimnames = list(rownames(econ_fin),\n",
    "                                                \"Refi_DP_TBL\"))\n",
    "\n",
    "# Set Time Parameter\n",
    "window_size <- 252 * 5\n",
    "t_start <- window_size\n",
    "t_end <- nrow(data) - 1\n",
    "t_seq <- seq(t_start, t_end)\n",
    "adj <- nrow(econ_fin) - nrow(data)\n",
    "\n",
    "# Loop over Rolling Window\n",
    "for (t in t_seq) {\n",
    "\n",
    "  # Train Data\n",
    "  x_train <- data[(t - window_size + 1):t, -1, drop = FALSE]\n",
    "  y_train <- data[(t - window_size + 1):t,  1, drop = FALSE]\n",
    "\n",
    "  # Test Data\n",
    "  x_pred  <- data[(t + 1), -1, drop = FALSE]\n",
    "  y_pred  <- data[(t + 1),  1, drop = FALSE]\n",
    "\n",
    "  # Fit and Predict\n",
    "  pred_dp_tbl[t + 1 + adj, ] <- cm_dp_tbl(x_train,\n",
    "                                          y_train,\n",
    "                                          x_pred)\n",
    "}\n",
    "\n",
    "# Convert to Tibble and Save\n",
    "pred_dp_tbl <- pred_dp_tbl %>%\n",
    "  as_tibble(rownames = \"Date\") %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/F_Signals/refi_dp_tbl.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"econ_fin\", \"data\", \"pred_dp_tbl\",\n",
    "            \"window_size\", \"t_start\", \"t_end\", \"t_seq\", \"adj\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "### Principal Component Regression Forecast\n",
    "# Load Custom Function\n",
    "source(glue(\"{path}/Code/_cmodels.R\"), local = TRUE)\n",
    "\n",
    "# Load Data\n",
    "econ_fin <- read_rds(glue(\"{path}/Data/ES1/P_Signals/Econ_Fin/econ_fin_signals.rds\")) %>%\n",
    "  column_to_rownames(\"Date\") %>%\n",
    "  mutate(across(!equity_premium, dplyr::lag))\n",
    "\n",
    "# Drop Na-Values\n",
    "data <- econ_fin %>%\n",
    "  drop_na() %>%\n",
    "  as.matrix()\n",
    "\n",
    "# Result-Object: Predictions\n",
    "pred_pcr <- matrix(NA, nrow = nrow(econ_fin),\n",
    "                   ncol = 1, dimnames = list(rownames(econ_fin),\n",
    "                                             \"Refi_PCR_Econ_Fin\"))\n",
    "# Set Time Parameter\n",
    "window_size <- 252 * 5\n",
    "t_start <- window_size\n",
    "t_end <- nrow(data) - 1\n",
    "t_seq <- seq(t_start, t_end)\n",
    "adj <- nrow(econ_fin) - nrow(data)\n",
    "\n",
    "# Set Tuning Parameter\n",
    "n_comp <- 10\n",
    "val <- TRUE\n",
    "\n",
    "# Parallel-Backend\n",
    "cores <- 4\n",
    "cl <- parallel::makeCluster(cores)\n",
    "clusterExport(cl = cl, varlist = c(\"data\",\n",
    "                                   \"window_size\",\n",
    "                                   \"n_comp\",\n",
    "                                   \"val\",\n",
    "                                   \"cm_pcr\"), envir = environment())\n",
    "pbo <- pbapply::pboptions(type = \"timer\")\n",
    "\n",
    "# Perform predictions in parallel\n",
    "pred_pcr[t_seq + adj + 1, ] <- do.call(\"rbind\", pbapply::pblapply(cl = cl, X = t_seq, FUN = function(t) {\n",
    "\n",
    "  # Train Data\n",
    "  x_train <- data[(t - window_size + 1):t, -1, drop = FALSE]\n",
    "  y_train <- data[(t - window_size + 1):t,  1, drop = FALSE]\n",
    "\n",
    "  # Test Data\n",
    "  x_pred <- data[(t + 1), -1, drop = FALSE]\n",
    "  y_pred <- data[(t + 1),  1, drop = FALSE]\n",
    "\n",
    "  # Fit and Predict\n",
    "  pred <- cm_pcr(x_train,\n",
    "                 y_train,\n",
    "                 x_pred,\n",
    "                 n_comp,\n",
    "                 val)\n",
    "  # Return\n",
    "  return(pred)\n",
    "}))\n",
    "\n",
    "# Stop Parallel Back-end\n",
    "parallel::stopCluster(cl)\n",
    "\n",
    "# Convert to Tibble and Save\n",
    "pred_pcr <- pred_pcr %>%\n",
    "  as_tibble(rownames = \"Date\") %>%\n",
    "  mutate(Date = ymd(Date)) %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/F_Signals/refi_pcr_econ_fin.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"econ_fin\", \"data\", \"pred_pcr\",\n",
    "            \"window_size\", \"t_start\", \"t_end\", \"t_seq\", \"adj\",\n",
    "            \"n_comp\", \"cores\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "######### --------------------------------------------\n",
    "# Create F-Signal Set\n",
    "# File Names\n",
    "file_names <- c(\"phm\",\n",
    "                \"refi_gbm\",\n",
    "                \"refi_dp_tbl\",\n",
    "                \"refi_pcr_econ_fin\")\n",
    "\n",
    "# Load and Join\n",
    "refi_set <- purrr::map(file_names, ~ read_rds(glue(\"{path}/Data/ES1/F_Signals/{.x}.rds\"))) %>%\n",
    "  purrr::reduce(left_join, by = \"Date\") %>%\n",
    "  write_rds(glue(\"{path}/Data/ES1/F_Signals/refined_signals.rds\"),\n",
    "            compress = \"gz\")\n",
    "\n",
    "# Display Dimensions\n",
    "cat(\"Number of Signals:\", ncol(refi_set), \"\\n\")\n",
    "cat(\"Number of Observations:\", nrow(refi_set), \"\\n\")\n",
    "\n",
    "# Clean environment\n",
    "rm(list = c(\"file_names\", \"refi_set\"))\n",
    "######### --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) LaTex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read Signal-Description-Excel\n",
    "readxl::read_excel(\"/Users/slehmann/Library/CloudStorage/Dropbox/HighFrequency_TextPredictors/Results/ES1/Signals/overview_signals.xlsx\", sheet = 2, col_types = \"text\") %>%\n",
    "  mutate(across(everything(), ~str_replace_all(., \"\\\\u2026\", \"...\"))) %>%\n",
    "  dplyr::slice(-1) %>%\n",
    "  replace(is.na(.), \"\") %>%\n",
    "  kableExtra::kbl(booktabs = T,\n",
    "                  caption = \"Signals for predicting daily U.S. stock returns\",\n",
    "                  format = \"latex\",\n",
    "                  escape = T) %>%\n",
    "  kableExtra::row_spec(0, bold = T) %>%\n",
    "  kableExtra::kable_styling(position = \"center\", latex_options = c(\"scale_down\")) %>%\n",
    "  kableExtra::pack_rows(\"Interest Rates (2)\", 1, 2, underline = F, bold = T, hline_before = F) %>%\n",
    "  kableExtra::pack_rows(\"Exchange Rates (10)\", 3, 12, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Moving-Average Indicator (10)\", 13, 14, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Price-Momentum (8)\", 15, 16, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Volume-Indicator (11)\", 17, 19, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Volatility (2)\", 20, 21, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Dividends (1)\", 22, 22, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Commodity (2)\", 23, 24, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"World Indices (5)\", 25, 29, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Sentiment (40)\", 30, 31, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Word Counts (12,288)\", 32, 32, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Topics (500)\", 33, 33, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::pack_rows(\"Ext. Point Forecasts (4)\", 34, 37, underline = F, bold = T, hline_before = T) %>%\n",
    "  kableExtra::footnote(general = \"NOTES: Excerpt from the menu of signals used for predicting daily U.S. equity premium. First model: (01/06/1954 - 12/31/1998): dp, TBL3M, TSP1, vola, PHM. Second Model (01/06/1954 - 12/31/2021): all 12,883 signals.\",\n",
    "                       footnote_as_chunk = TRUE,\n",
    "                       fixed_small_size = FALSE,\n",
    "                       threeparttable = TRUE,\n",
    "                       escape = F,\n",
    "                       general_title = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
